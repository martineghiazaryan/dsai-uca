{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "classical-aruba",
   "metadata": {},
   "source": [
    "**In this assignment you will be guided to add more features in order to get better performance!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "nasty-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "satisfactory-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "textile-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-spain",
   "metadata": {},
   "source": [
    "A simple sentence NER example:\n",
    "\n",
    "[**ORG** U.N. ] official [**PER** Ekeus ] heads for [**LOC** Baghdad ] \n",
    "\n",
    "We will concentrate on four types of named entities:\n",
    " * persons (**PER**), \n",
    " * locations (**LOC**) \n",
    " * organizations (**ORG**)\n",
    " * Others (**O**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "visible-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_examples(filepath):\n",
    "        with open(filepath, encoding=\"utf-8\") as f:\n",
    "            sent = []\n",
    "            for line in f:\n",
    "                if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":\n",
    "                    if sent:\n",
    "                        yield sent\n",
    "                        sent = []\n",
    "                else:\n",
    "                    splits = line.split(\" \")\n",
    "                    token = splits[0]\n",
    "                    pos_tag = splits[1]\n",
    "                    ner_tag = splits[3].rstrip()\n",
    "                    if 'MISC' in ner_tag:\n",
    "                        ner_tag = 'O'\n",
    "                    \n",
    "                    sent.append((token, pos_tag, ner_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "trying-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 184 ms, sys: 21.4 ms, total: 206 ms\n",
      "Wall time: 190 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_sents = list(_generate_examples('/home/taki/dt_df/CRF/train.txt'))\n",
    "test_sents = list(_generate_examples('/home/taki/dt_df/CRF/test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-renewal",
   "metadata": {},
   "source": [
    "Here we have succesfully loaded the trianing and test data.\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-occasions",
   "metadata": {},
   "source": [
    "Here is a list of english stopwords, and we would like to include it as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "north-jacob",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/taki/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-lancaster",
   "metadata": {},
   "source": [
    "Here is a list of names, and we would like to include it as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "explicit-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = set()\n",
    "with open('/home/taki/dt_df/CRF/names.txt') as f:\n",
    "    for l in f:\n",
    "        names.add(l[:-1].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-police",
   "metadata": {},
   "source": [
    "_____________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-civilization",
   "metadata": {},
   "source": [
    "You are asked to change the `word2features` function to add the following features:\n",
    "\n",
    "**For the current word**:\n",
    "1. Add a feature named `word.isupper()` that tells if the word is in upper case (you can your the `isupper()` function in python)\n",
    "2. Add a feature named `word.isdigit()` that tells if the word is all digits (similarility you can use the `isdigit()` built-in python function)\n",
    "3. Add a feature named `word.l1_is_capital` that tells if the word starts with a capital letter\n",
    "4. Add a feature named `word.ends_in_dot` that tells if the word has lenght > 1 and ends with a dot (`.`)\n",
    "5. Add a feature named `word.is_stop_word` that tells is the word belongs to the list of stop words defined previously `stop_words` (don't forget to convert the word into lower case before testing, just to be case insensitive)\n",
    "6. Add a feature named `word.constains_digits` that tells if the word contains a digit or not\n",
    "7. Add a feature names `word.figures_in_names_list` that tells if the word belongs to the list of names we defined previously `names`. Again don't forget to change the word into lower case first.\n",
    "\n",
    "**For the previous word**: (BE CAREFUL, YOU SHOULD NOT USE `word`, USE `word1` instead):\n",
    "\n",
    "Add the same features. Just prepend the name of features with `-1:` (It's important for the different features to be of different names)\n",
    "\n",
    "**Add infomration about nextword**: (BE CAREFUL, YOU SHOULD NOT USE `word`, USE `word1` instead):\n",
    "\n",
    "* Add the same features. Just prepend the name of features with `+1:` (It's important for the different features to be of different names)\n",
    "\n",
    "* **PS**: If the word is the last one in the sentence (no next word), just add a feature named `EOS` = True to tell that the word is in the last position. JUst as we've did with `BOS`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "qualified-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'postag': postag,\n",
    "        # Add features of the current word here\n",
    "    }\n",
    "    \n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:postag': postag1,\n",
    "            # Add features of previous word here\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    # Similariliy, add features of the next word here.\n",
    "\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "synthetic-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-saturn",
   "metadata": {},
   "source": [
    "Construct the features for the training and test test\n",
    "_________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-atlanta",
   "metadata": {},
   "source": [
    "Train your CRF\n",
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-dispute",
   "metadata": {},
   "source": [
    "Compute F1 score for different labels. Remove the 'O' label before that\n",
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-notion",
   "metadata": {},
   "source": [
    "Show the 20 top and 20 least likely transitions between labels \n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-packaging",
   "metadata": {},
   "source": [
    "Show the 50 top and 50 least likely state features (compatibility between features and labels)\n",
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-boxing",
   "metadata": {},
   "source": [
    "See if you can spot some interesting features (both with positive and negative coefficients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
